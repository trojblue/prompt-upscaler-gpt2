{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, PngImagePlugin\n",
    "import hashlib\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import unibox as ub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt2 client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://e45d0e6c55d3364043.gradio.live/ ✔\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hatsune miku, 1girl, blonde hair, twintails, closed eyes, open mouth, smile, hair ornament, very long hair, sleeveless, white dress, hair flower, outdoors, outstretched arms, bare shoulders, bangs, :d, white footwear, armpits, hair between eyes, arm up, blurry background, depth of field, spread arms, standing on one leg, cloudy sky, pink flower, full body, white pantyhose, VOCALOI'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gpt2 api\n",
    "from gradio_client import Client\n",
    "\n",
    "GPT2_ENDPOINT = \"https://e45d0e6c55d3364043.gradio.live/\"\n",
    "client = Client(GPT2_ENDPOINT) # version epoch_0_batch_11727\n",
    "\n",
    "\n",
    "def get_gpt2_pred(prompt, max_length):\n",
    "\t# prompt: str\n",
    "\t# max_length: float (numeric value between 10 and 300)\n",
    "\t# return: str\n",
    "\tresult = client.predict(\n",
    "\t\tprompt,\n",
    "\t\tmax_length,\n",
    "\t\tapi_name=\"/predict\"\n",
    "\t)\n",
    "\treturn result\n",
    "\n",
    "get_gpt2_pred(\"hatsune miku\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "webui:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/troph-team/eval-it/blob/aa0cb59983e2b0385ef03328b2ce6a3c36a073a0/evalit/webui/webui_t2i_client.py#L38C7-L38C27\n",
    "from evalit.webui.webui_t2i_client import WebuiT2iClient\n",
    "from evalit.webui.webui_t2i_client import WebuiT2iClient, SdxlGenerationConfig\n",
    "from evalit.webui.webui_options_manager import OptionsManager\n",
    "\n",
    "\n",
    "def save_image(image_paths:list[str], param_strs:list[str], api_args, save_dir:str=\"saved_images\"):\n",
    "    \"\"\"保存一个webui生成结果到本地 (可能包括多张图)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    saved_files = []\n",
    "\n",
    "    for i, (image, param) in enumerate(zip(image_paths, param_strs)):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        pnginfo = PngImagePlugin.PngInfo()\n",
    "        pnginfo.add_text(\"parameters\", param)\n",
    "        pnginfo.add_text(\"api_args\", json.dumps(api_args))\n",
    "\n",
    "        # get filename\n",
    "        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        img_hash = hashlib.md5(image.tobytes()).hexdigest()        \n",
    "        file_name = f\"{timestamp}_{img_hash[:4]}.png\"        \n",
    "        file_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "        # save file\n",
    "        image.save(file_path, pnginfo=pnginfo)\n",
    "        saved_files.append(file_path)  # Add the saved file path to the list\n",
    "\n",
    "    return saved_files\n",
    "\n",
    "def generate_and_save_images(prompt:str, save_dir:str=\"saved_images\"):\n",
    "    \"\"\"从webui api roll图, 然后返回本地保存路径\n",
    "    (假设模型已经在webui里手动调到需要的那个)\n",
    "    \"\"\"\n",
    "    # initialize client\n",
    "    client = WebuiT2iClient(baseurl=\"http://0.0.0.0:7862\")\n",
    "\n",
    "    # initialize options manager\n",
    "    client_base_url = client.baseurl\n",
    "    options_manager = OptionsManager(client_base_url)\n",
    "\n",
    "    # https://github.com/troph-team/eval-it/blob/aa0cb59983e2b0385ef03328b2ce6a3c36a073a0/evalit/webui/webui_t2i_client.py#L38  \n",
    "    config = SdxlGenerationConfig() \n",
    "    config.sampler_name=\"Euler a\"\n",
    "    config.steps=24\n",
    "    config.cfg_scale=6.5\n",
    "\n",
    "    # generate images\n",
    "    images, param_strs, api_args = client.generate(prompt, config)  # negative defined in config\n",
    "\n",
    "    # save images\n",
    "    saved_files = save_image(images, param_strs, api_args, save_dir) # list of paths to saved images\n",
    "    return saved_files\n",
    "\n",
    "# save_dir = \"saved_images\"\n",
    "# img_path = generate_and_save_images(\"a cat\")[0]\n",
    "# display(ub.loads(img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def roll_image(prompt:str):\n",
    "    print(\"got prompt\", prompt)\n",
    "    orig_prompt = prompt\n",
    "\n",
    "    augmented_prompt = get_gpt2_pred(prompt, 60)\n",
    "    print(\"got augmented prompt\", augmented_prompt)\n",
    "\n",
    "    orig_img_results = generate_and_save_images(orig_prompt)\n",
    "    print(f\"got image0: {orig_img_results}\")\n",
    "\n",
    "    augmented_img_results = generate_and_save_images(augmented_prompt)\n",
    "    print(f\"got image1: {augmented_img_results}\")\n",
    "    \n",
    "    img_paths = [orig_img_results[0], augmented_img_results[0]]\n",
    "    imgs = [ub.loads(img_path) for img_path in img_paths]\n",
    "\n",
    "    # stitch horizontally\n",
    "    stitch_img = Image.new('RGB', (imgs[0].width + imgs[1].width, imgs[0].height))\n",
    "    stitch_img.paste(imgs[0], (0, 0))\n",
    "    stitch_img.paste(imgs[1], (imgs[0].width, 0))\n",
    "    print(\"stitched images\")\n",
    "\n",
    "    prompt_return_str = f\"**Original:** {orig_prompt}\\n\\n**Augmented:** {augmented_prompt}\"\n",
    "\n",
    "    return prompt_return_str, stitch_img\n",
    "\n",
    "description = \"\"\"# LM-Augmented SDXL Demo\n",
    " Augments the input prompt with gpt-2, then generates 2 images for comparison. takes about 20 seconds to run.\n",
    " - model: fulldan-5m-9e \n",
    " - generation config: Euler a; cfg6.5; 24 steps\n",
    "\"\"\"\n",
    "\n",
    "inputs = [gr.Textbox(label=\"Enter prompt (comma-separated danbooru tags)\", placeholder=\"hatsune miku\"), ]\n",
    "outputs = [\n",
    "    gr.Textbox(label=\"Generated Prompts\"), \n",
    "    gr.Image(label=\"Generated Images\"), \n",
    "    ]\n",
    "\n",
    "# Define the Gradio interface\n",
    "interface = gr.Interface(fn=roll_image,\n",
    "                         inputs=inputs,\n",
    "                         outputs=outputs,\n",
    "                         description=description,\n",
    "                         )\n",
    "\n",
    "# Launch the Gradio app\n",
    "interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
