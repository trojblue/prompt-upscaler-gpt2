{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from PIL import Image, PngImagePlugin\n",
    "\n",
    "import unibox as ub\n",
    "logger = ub.UniLogger()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt2 client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt2 api\n",
    "from gradio_client import Client\n",
    "\n",
    "def get_gpt2_pred_old(client, prompt:str, max_length:int, models:list[str]):\n",
    "\t# prompt: str\n",
    "\t# max_length: float (numeric value between 10 and 300)\n",
    "\t# return: str\n",
    "\tresult = client.predict(\n",
    "\t\tprompt,\n",
    "\t\tmax_length,\n",
    "\t\tmodels,\n",
    "\t\tapi_name=\"/predict\"\n",
    "\t)\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_gpt2_pred(client, rating:str, character:str, prompt:str, max_length:int, models:list[str]):\n",
    "\t\n",
    "\tassert rating in ['safe', 'sensitive', 'nsfw', 'nsfw, explicit']\n",
    "\t\n",
    "\tresult = client.predict(\n",
    "\t\t\trating,\t# Literal['safe', 'sensitive', 'nsfw', 'nsfw, explicit'] in 'Rating' Radio component\n",
    "\t\t\t\"2020s\",\t# Literal['2000s', '2010s', '2015s', '2020s'] in 'Date' Radio component\n",
    "\t\t\t\"excellent\",\t# Literal['bad', 'normal', 'good', 'excellent'] in 'Quality' Radio component\n",
    "\t\t\tcharacter,\t# str in 'Character' Textbox component\n",
    "\t\t\tprompt,\t# str in 'prompt' Textbox component\n",
    "\t\t\tmax_length,\t# float (numeric value between 40 and 300) in 'max_length' Slider component\n",
    "\t\t\tmodels,\t# List[Literal['checkpoint-e0_s12000', 'checkpoint-e0_s28000', 'checkpoint-e0_s48000']] in 'Select Models' Checkboxgroup component\n",
    "\t\t\tapi_name=\"/predict\"\n",
    "\t)\n",
    "\treturn result\n",
    "\n",
    "\n",
    "# GPT2_ENDPOINT = \"https://ab2b7e0b874cc07fb9.gradio.live/\"\n",
    "# client = Client(GPT2_ENDPOINT) # version epoch_0_batch_11727\n",
    "# get_gpt2_pred(client, \"hatsune miku\", 100, [\"epoch_0_batch_17619\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "webui:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/troph-team/eval-it/blob/aa0cb59983e2b0385ef03328b2ce6a3c36a073a0/evalit/webui/webui_t2i_client.py#L38C7-L38C27\n",
    "from evalit.webui.webui_t2i_client import WebuiT2iClient\n",
    "from evalit.webui.webui_t2i_client import WebuiT2iClient, SdxlGenerationConfig\n",
    "from evalit.webui.webui_options_manager import OptionsManager\n",
    "\n",
    "\n",
    "def save_image(image_paths:list[str], param_strs:list[str], api_args, save_dir:str=\"saved_images\"):\n",
    "    \"\"\"保存一个webui生成结果到本地 (可能包括多张图)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    saved_files = []\n",
    "\n",
    "    for i, (image, param) in enumerate(zip(image_paths, param_strs)):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        pnginfo = PngImagePlugin.PngInfo()\n",
    "        pnginfo.add_text(\"parameters\", param)\n",
    "        pnginfo.add_text(\"api_args\", json.dumps(api_args))\n",
    "\n",
    "        # get filename\n",
    "        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        img_hash = hashlib.md5(image.tobytes()).hexdigest()        \n",
    "        file_name = f\"{timestamp}_{img_hash[:4]}.png\"        \n",
    "        file_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "        # save file\n",
    "        image.save(file_path, pnginfo=pnginfo)\n",
    "        saved_files.append(file_path)  # Add the saved file path to the list\n",
    "\n",
    "    return saved_files\n",
    "\n",
    "def generate_and_save_images(prompt:str, config:SdxlGenerationConfig, save_dir:str=\"saved_images\",):\n",
    "    \"\"\"从webui api roll图, 然后返回本地保存路径\n",
    "    (假设模型已经在webui里手动调到需要的那个)\n",
    "    \"\"\"\n",
    "    # initialize client\n",
    "    client = WebuiT2iClient(baseurl=\"http://0.0.0.0:7862\")\n",
    "\n",
    "    # initialize options manager\n",
    "    client_base_url = client.baseurl\n",
    "    options_manager = OptionsManager(client_base_url)\n",
    "\n",
    "\n",
    "    # generate images\n",
    "    images, param_strs, api_args = client.generate(prompt, config)  # negative defined in config\n",
    "\n",
    "    # save images\n",
    "    saved_files = save_image(images, param_strs, api_args, save_dir) # list of paths to saved images\n",
    "    return saved_files\n",
    "\n",
    "# save_dir = \"saved_images\"\n",
    "# img_path = generate_and_save_images(\"a cat\")[0]\n",
    "# display(ub.loads(img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://44b07123159cab6c40.gradio.live/ ✔\n",
      "Running on local URL:  http://127.0.0.1:7863\n",
      "Running on public URL: https://df168bfa1186ccc13f.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://df168bfa1186ccc13f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 21:26:30,533 [INFO] UniLogger: roll_image: got prompt: 1girl\n",
      "2024-03-19 21:26:32,218 [INFO] UniLogger: roll_image: got gpt2 res of len=2\n",
      "2024-03-19 21:26:52,060 [INFO] UniLogger: roll_image: model: original | prompt: <input rating=\"safe\" chara=\"\" date=\"2020s\" quality=\"excellent\" tags=\"1girl\"><output> | image: ['saved_images/20240319212651_9285.png']\n",
      "2024-03-19 21:27:11,377 [INFO] UniLogger: roll_image: model: 8xh100_run2_e2_s50k | prompt: 1girl, mole under eye, underwear, green eyes, blue eyes, looking at viewer, white legwear, panties under pantyhose, bare shoulders, collarbone, medium breasts, nail polish, crotch seam, see-through, cowboy shot, parted lips, eyebrows visible through hair, standing, white pantyhose, kaede takagaki, the idolmaster: cinderella girls, cleavage | image: ['saved_images/20240319212711_f2e5.png']\n",
      "2024-03-19 21:27:11,378 [INFO] UniLogger: UniLoader.loads: .png LOADED from \"saved_images/20240319212651_9285.png\" in 0.00s\n",
      "2024-03-19 21:27:11,379 [INFO] UniLogger: UniLoader.loads: .png LOADED from \"saved_images/20240319212711_f2e5.png\" in 0.00s\n",
      "2024-03-19 21:27:11,438 [INFO] UniLogger: roll_image: stitched images\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "def get_sdxl_generation_config(steps:int=24):\n",
    "    \"\"\"returns a SdxlGenerationConfig object with modifiable steps param\n",
    "    \"\"\"\n",
    "    \n",
    "    # SDXL generation config\n",
    "    # https://github.com/troph-team/eval-it/blob/aa0cb59983e2b0385ef03328b2ce6a3c36a073a0/evalit/webui/webui_t2i_client.py#L38  \n",
    "    config = SdxlGenerationConfig() \n",
    "    config.sampler_name=\"Euler a\"\n",
    "    config.cfg_scale=6.5\n",
    "    config.height=1280\n",
    "    config.width=768\n",
    "    config.steps=steps\n",
    "\n",
    "    return SdxlGenerationConfig()\n",
    "\n",
    "\n",
    "def stitch_images_horizontally(imgs:list[Image.Image]):\n",
    "    \"\"\"横向拼接多张图片\"\"\"\n",
    "    stitch_img = Image.new('RGB', (imgs[0].width * len(imgs), imgs[0].height))\n",
    "    for i, img in enumerate(imgs):\n",
    "        stitch_img.paste(img, (img.width * i, 0))\n",
    "    return stitch_img\n",
    "\n",
    "\n",
    "def roll_image(rating:str, character:str, prompt:str, prompt_len:int, img_steps:int, prompt_only:bool):\n",
    "\n",
    "    orig_prompt = prompt\n",
    "    logger.info(f\"got prompt: {prompt}\")\n",
    "\n",
    "    # get gpt2 predictions\n",
    "    gpt2_res = get_gpt2_pred(client, rating, character, prompt, prompt_len, gpt2_models)\n",
    "    logger.info(f\"got gpt2 res of len={len(gpt2_res)}\")\n",
    "\n",
    "    # get prompt return string\n",
    "    prompt_return_str = \"\\n\\n\".join([f\"[{k}] {v}\" for k, v in gpt2_res.items()])\n",
    "    \n",
    "    if prompt_only:\n",
    "        return prompt_return_str, None\n",
    "\n",
    "\n",
    "    # generate images with webui API\n",
    "    img_results = []\n",
    "    config = get_sdxl_generation_config(steps=img_steps)\n",
    "    for model_key, model_res in gpt2_res.items():\n",
    "        _model_res = model_res.replace(\"</output>\", \"\")\n",
    "        curr_img_results = generate_and_save_images(prompt=_model_res, config=config)\n",
    "        logger.info(f\"model: {model_key} | prompt: {_model_res} | image: {curr_img_results}\")\n",
    "        img_results.append(curr_img_results)\n",
    "    \n",
    "    # load iamge paths to PIL\n",
    "    image_paths = [curr_img_res[0] for curr_img_res in img_results]\n",
    "    imgs = [ub.loads(img_path) for img_path in image_paths] # list of PIL images\n",
    "    \n",
    "    # stitch images horizontally\n",
    "    stitch_img = stitch_images_horizontally(imgs)\n",
    "    logger.info(\"stitched images\")\n",
    "\n",
    "    return prompt_return_str, stitch_img\n",
    "\n",
    "gpt2_models = [\n",
    "    # 'checkpoint-e0_s32000',\n",
    "    # 'checkpoint-e0_s68000',\n",
    "    '8xh100_run2_e2_s50k',\n",
    "]\n",
    "\n",
    "\n",
    "description = f\"\"\"\n",
    "# LM-Augmented SDXL Demo\n",
    "Augments the input prompt with gpt-2, then generates 2 images for comparison. takes about 50 seconds to run.\n",
    " - generated prompts: {\" | \".join([\"original\"] + gpt2_models)}\n",
    " - generation config: Euler a | cfg6.5\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "GPT2_ENDPOINT = \"https://44b07123159cab6c40.gradio.live\"\n",
    "client = Client(GPT2_ENDPOINT) # version epoch_0_batch_11727\n",
    "\n",
    "\n",
    "inputs = [\n",
    "    gr.Radio(choices=[\"safe\", \"sensitive\", \"nsfw\", \"nsfw, explicit\"], label=\"Rating\", value=\"safe\"),\n",
    "    gr.Textbox(lines=1, placeholder=\"Enter your prompt here...\", label=\"Character\"),\n",
    "    gr.Textbox(label=\"Enter prompt (comma-separated danbooru tags recommended)\", placeholder=\"hatsune miku, aqua hair\"), \n",
    "    gr.Slider(label=\"Prompt Length\", minimum=60, maximum=300, step=10, value=160),\n",
    "    gr.Slider(label=\"Image Steps\", minimum=8, maximum=40, step=2, value=18),\n",
    "    gr.Checkbox(label=\"Prompt Only\", value=False),\n",
    "    ]\n",
    "outputs = [\n",
    "    gr.Textbox(label=\"Generated Prompts\"), \n",
    "    gr.Image(label=\"Generated Images\"), \n",
    "    ]\n",
    "\n",
    "# Define the Gradio interface\n",
    "interface = gr.Interface(fn=roll_image,\n",
    "                         inputs=inputs,\n",
    "                         outputs=outputs,\n",
    "                         description=description,\n",
    "                         )\n",
    "\n",
    "# Launch the Gradio app\n",
    "interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
