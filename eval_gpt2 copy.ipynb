{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from PIL import Image, PngImagePlugin\n",
    "\n",
    "import unibox as ub\n",
    "logger = ub.UniLogger()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt2 client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://ab2b7e0b874cc07fb9.gradio.live/ ✔\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'original': 'hatsune miku',\n",
       " 'epoch_0_batch_17619': 'hatsune miku, 1girl, twintails, thighhighs, very long hair, aqua hair, detached sleeves, necktie, nail polish, aqua eyes, smile, blush, zettai ryouiki, open mouth, headphones, striped, headphones around neck, black legwear, hair ornament, shirt, 39, miku100, long hair, solo, skirt, headset, headphones, green hair, ahoge, thighhighs, tattoo, ahoge over one ey'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gpt2 api\n",
    "from gradio_client import Client\n",
    "\n",
    "GPT2_ENDPOINT = \"https://ab2b7e0b874cc07fb9.gradio.live/\"\n",
    "client = Client(GPT2_ENDPOINT) # version epoch_0_batch_11727\n",
    "\n",
    "\n",
    "\n",
    "def get_gpt2_pred(client, prompt:str, max_length:int, models:list[str]):\n",
    "\t# prompt: str\n",
    "\t# max_length: float (numeric value between 10 and 300)\n",
    "\t# return: str\n",
    "\tresult = client.predict(\n",
    "\t\tprompt,\n",
    "\t\tmax_length,\n",
    "\t\tmodels,\n",
    "\t\tapi_name=\"/predict\"\n",
    "\t)\n",
    "\treturn result\n",
    "\n",
    "get_gpt2_pred(client, \"hatsune miku\", 100, [\"epoch_0_batch_17619\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "webui:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/troph-team/eval-it/blob/aa0cb59983e2b0385ef03328b2ce6a3c36a073a0/evalit/webui/webui_t2i_client.py#L38C7-L38C27\n",
    "from evalit.webui.webui_t2i_client import WebuiT2iClient\n",
    "from evalit.webui.webui_t2i_client import WebuiT2iClient, SdxlGenerationConfig\n",
    "from evalit.webui.webui_options_manager import OptionsManager\n",
    "\n",
    "\n",
    "def save_image(image_paths:list[str], param_strs:list[str], api_args, save_dir:str=\"saved_images\"):\n",
    "    \"\"\"保存一个webui生成结果到本地 (可能包括多张图)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    saved_files = []\n",
    "\n",
    "    for i, (image, param) in enumerate(zip(image_paths, param_strs)):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        pnginfo = PngImagePlugin.PngInfo()\n",
    "        pnginfo.add_text(\"parameters\", param)\n",
    "        pnginfo.add_text(\"api_args\", json.dumps(api_args))\n",
    "\n",
    "        # get filename\n",
    "        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        img_hash = hashlib.md5(image.tobytes()).hexdigest()        \n",
    "        file_name = f\"{timestamp}_{img_hash[:4]}.png\"        \n",
    "        file_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "        # save file\n",
    "        image.save(file_path, pnginfo=pnginfo)\n",
    "        saved_files.append(file_path)  # Add the saved file path to the list\n",
    "\n",
    "    return saved_files\n",
    "\n",
    "def generate_and_save_images(prompt:str, save_dir:str=\"saved_images\"):\n",
    "    \"\"\"从webui api roll图, 然后返回本地保存路径\n",
    "    (假设模型已经在webui里手动调到需要的那个)\n",
    "    \"\"\"\n",
    "    # initialize client\n",
    "    client = WebuiT2iClient(baseurl=\"http://0.0.0.0:7862\")\n",
    "\n",
    "    # initialize options manager\n",
    "    client_base_url = client.baseurl\n",
    "    options_manager = OptionsManager(client_base_url)\n",
    "\n",
    "    # https://github.com/troph-team/eval-it/blob/aa0cb59983e2b0385ef03328b2ce6a3c36a073a0/evalit/webui/webui_t2i_client.py#L38  \n",
    "    config = SdxlGenerationConfig() \n",
    "    config.sampler_name=\"Euler a\"\n",
    "    config.steps=24\n",
    "    config.cfg_scale=6.5\n",
    "    config.height=1280\n",
    "    config.width=768\n",
    "\n",
    "    # generate images\n",
    "    images, param_strs, api_args = client.generate(prompt, config)  # negative defined in config\n",
    "\n",
    "    # save images\n",
    "    saved_files = save_image(images, param_strs, api_args, save_dir) # list of paths to saved images\n",
    "    return saved_files\n",
    "\n",
    "# save_dir = \"saved_images\"\n",
    "# img_path = generate_and_save_images(\"a cat\")[0]\n",
    "# display(ub.loads(img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "Running on public URL: https://4a7ae081d8b932fca0.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4a7ae081d8b932fca0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 22:21:36,622 [INFO] UniLogger: roll_image: got prompt: 1girl, long hair, white hair\n",
      "2024-03-16 22:21:39,403 [INFO] UniLogger: roll_image: got gpt2 res of len=4\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.10/site-packages/gradio/queueing.py\", line 501, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.10/site-packages/gradio/route_utils.py\", line 253, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1695, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1235, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.10/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.10/site-packages/gradio/utils.py\", line 692, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_218030/3790552265.py\", line 32, in roll_image\n",
      "    logger.info(f\"model: {model_key} | prompt: {model_res} | image: {orig_img_results}\")\n",
      "NameError: name 'orig_img_results' is not defined. Did you mean: 'curr_img_results'?\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "gpt2_models = [\n",
    "    'epoch_0_batch_17619',\n",
    "    'epoch_0_batch_52986',\n",
    "    'epoch_0_batch_120933',\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def stitch_images_horizontally(imgs:list[Image.Image]):\n",
    "    \"\"\"横向拼接多张图片\"\"\"\n",
    "    stitch_img = Image.new('RGB', (imgs[0].width * len(imgs), imgs[0].height))\n",
    "    for i, img in enumerate(imgs):\n",
    "        stitch_img.paste(img, (img.width * i, 0))\n",
    "    return stitch_img\n",
    "\n",
    "\n",
    "def roll_image(prompt:str):\n",
    "\n",
    "    orig_prompt = prompt\n",
    "    logger.info(f\"got prompt: {prompt}\")\n",
    "\n",
    "    gpt2_res = get_gpt2_pred(client, prompt, 60, gpt2_models)\n",
    "    logger.info(f\"got gpt2 res of len={len(gpt2_res)}\")\n",
    "\n",
    "    img_results = []\n",
    "    for model_key, model_res in gpt2_res.items():\n",
    "        curr_img_results = generate_and_save_images(model_res)\n",
    "        logger.info(f\"model: {model_key} | prompt: {model_res} | image: {curr_img_results}\")\n",
    "        img_results.append(curr_img_results)\n",
    "    \n",
    "    image_paths = [curr_img_res[0] for curr_img_res in img_results]\n",
    "    imgs = [ub.loads(img_path) for img_path in img_paths] # list of PIL images\n",
    "\n",
    "    # stitch horizontally\n",
    "    stitch_img = stitch_images_horizontally(imgs)\n",
    "    logger.info(\"stitched images\")\n",
    "\n",
    "    prompt_return_str = \"\\n\\n\".join([f\"[{k}] {v}\" for k, v in gpt2_res.items()])\n",
    "\n",
    "    return prompt_return_str, stitch_img\n",
    "\n",
    "description = f\"\"\"# LM-Augmented SDXL Demo\n",
    " Augments the input prompt with gpt-2, then generates 2 images for comparison. takes about 30 seconds to run.\n",
    " - generated prompts: {\" | \".join(gpt2_models)}\n",
    " - generation config: Euler a | cfg6.5 | **24 steps**\n",
    "\"\"\"\n",
    "\n",
    "inputs = [gr.Textbox(label=\"Enter prompt (comma-separated danbooru tags)\", placeholder=\"hatsune miku\"), ]\n",
    "outputs = [\n",
    "    gr.Textbox(label=\"Generated Prompts\"), \n",
    "    gr.Image(label=\"Generated Images\"), \n",
    "    ]\n",
    "\n",
    "# Define the Gradio interface\n",
    "interface = gr.Interface(fn=roll_image,\n",
    "                         inputs=inputs,\n",
    "                         outputs=outputs,\n",
    "                         description=description,\n",
    "                         )\n",
    "\n",
    "# Launch the Gradio app\n",
    "interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
