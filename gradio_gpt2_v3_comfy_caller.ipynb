{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT V3\n",
    "\n",
    "单个模型(fixed), 直接对接到webui (生成很多个), 所以产生一行一个的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import gradio as gr\n",
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "import os\n",
    "import hashlib\n",
    "import json\n",
    "from datetime import datetime\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "# Assuming DEVICE is already defined\n",
    "DEVICE = 'cuda'  # Use 'cuda' for GPU or 'cpu' for CPU\n",
    "\n",
    "# Path to the models' directories\n",
    "MODEL_DIRS = [\n",
    "    'pixiv-prompts-gpt-finetunes/8xh100_run2_e2_s50k',\n",
    "]\n",
    "\n",
    "# Load models and tokenizers from directories\n",
    "models = {}\n",
    "tokenizers = {}\n",
    "for model_dir in MODEL_DIRS:\n",
    "    model_name = os.path.basename(os.path.normpath(model_dir))\n",
    "    models[model_name] = transformers.GPT2LMHeadModel.from_pretrained(model_dir).to(DEVICE)\n",
    "    tokenizers[model_name] = transformers.AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "\n",
    "# Hardcoded model name\n",
    "HARDCODED_MODEL_NAME = os.path.basename(os.path.normpath(MODEL_DIRS[0]))\n",
    "\n",
    "def generate_text(rating: str, date: str, quality: str, character: str, prompt: str, max_length: int, num_lines: int, selected_models: list):\n",
    "    \"\"\"Generate text based on input prompt for selected models, managing multiple lines output.\"\"\"\n",
    "    query_prompt = f'<input rating=\"{rating}\" chara=\"{character}\" date=\"{date}\" quality=\"{quality}\" tags=\"{prompt}\">'\n",
    "    query_prompt += \"<output>\"\n",
    "\n",
    "    all_outputs = []\n",
    "    for model_name in selected_models:\n",
    "        model = models[model_name].eval()  # Set the model to evaluation mode\n",
    "        tokenizer = tokenizers[model_name]\n",
    "        for _ in range(num_lines):\n",
    "            input_ids = tokenizer.encode(query_prompt, return_tensors='pt').to(DEVICE)\n",
    "            output_sequences = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_length=max_length + len(input_ids[0]),\n",
    "                temperature=1.0,\n",
    "                top_k=50,\n",
    "                top_p=0.95,\n",
    "                repetition_penalty=1.0,\n",
    "                do_sample=True,\n",
    "                num_return_sequences=1,\n",
    "            )\n",
    "\n",
    "            generated_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "\n",
    "            # Find and remove the initial part up to <output>\n",
    "            start_output = generated_text.find(\"<output>\") + len(\"<output>\")\n",
    "            generated_text = generated_text[start_output:].strip()\n",
    "\n",
    "            # Remove the ending </output> tag or truncate at last complete tag\n",
    "            end_tag = generated_text.find(\"</output>\")\n",
    "            if end_tag != -1:\n",
    "                generated_text = generated_text[:end_tag]\n",
    "            else:\n",
    "                last_comma = generated_text.rfind(\",\")\n",
    "                if last_comma != -1:\n",
    "                    generated_text = generated_text[:last_comma]\n",
    "\n",
    "            all_outputs.append(generated_text.strip())\n",
    "\n",
    "    # Join all outputs into a single string separated by new lines\n",
    "    return \"\\n\".join(all_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_OUTPUT_DIR = \"generated_images\"\n",
    "\n",
    "\n",
    "def save_images_and_metadata(gend_images, gend_text, prompt):\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(IMG_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    for image in gend_images:\n",
    "        # Get filename\n",
    "        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        img_hash = hashlib.md5(image.tobytes()).hexdigest()        \n",
    "        file_name = f\"{timestamp}_{img_hash[:4]}.webp\"        \n",
    "        file_path = os.path.join(IMG_OUTPUT_DIR, file_name)\n",
    "        \n",
    "        # Save image\n",
    "        image.save(file_path, format='WEBP')\n",
    "\n",
    "        # Create metadata JSON\n",
    "        metadata = {\n",
    "            \"prompt\": prompt,\n",
    "            \"generated_text\": gend_text,\n",
    "        }\n",
    "        json_file_name = f\"{timestamp}_{img_hash[:4]}.json\"\n",
    "        json_file_path = os.path.join(IMG_OUTPUT_DIR, json_file_name)\n",
    "        \n",
    "        with open(json_file_path, 'w') as json_file:\n",
    "            json.dump(metadata, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://638551f6b54cddbfa6.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://638551f6b54cddbfa6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60597259f39140ff99056f29ffe5ae7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: multiple girls, 2girls, pantyhose, blonde hair, multicolored hair, green eyes, streaked hair, black legwear, very long hair, looking at viewer, grey background, purple headwear, long sleeves, simple background, medium breasts, puffy sleeves, eyebrows visible through hair, hair between eyes, closed mouth, white skirt, red jacket, black headwear, hair intakes, white dress, juliet sleeves, military uniform, zettai ryouiki, pleated skirt, cowboy shot, white jacket, underbust, corset, black necktie, belt pouch, miniskirt, black skirt, black shorts, double-breasted, buttons, collared shirt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5b2c7d4c1f4a3db6c150d8c5527061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: 1girl, open mouth, smile, school uniform, looking at viewer, upper body, green eyes, long sleeves, white sailor collar, serafuku, hand up, collarbone, signature, :d, multicolored hair, eyebrows visible through hair, sleeves past wrists, pink hair, neckerchief, white background, polka dot background, yellow cardigan, blunt bangs, medium breasts, two-tone hair, arm behind back, luna himemori, sailor uniform\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215883770f784ff38f4d5f6dbe5dd662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: 1girl, virtual youtuber, looking at viewer, yellow eyes, silver hair, multicolored hair, feathered wings, bare shoulders, blue hair, star (sky), bangs, closed mouth, night sky, outdoors, very long hair, sleeveless dress, angel wings, hair between eyes, small breasts, hair ornament, twintails, two-tone hair, cleavage, medium breasts, colored inner hair, expressionless, official alternate hairstyle, official alternate hair length, shooting star, purple hair, streaked hair, ai illustration, beautiful girl, young girl, kanata amane fanart\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db7293619754cb4bdec2406c1f76384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: 1girl, purple hair, japanese clothes, purple eyes, long hair, mole under eye, hair ornament, cleavage, electricity, obijime, holding weapon, looking at viewer, holding sword, purple flower, tomoe (symbol), shoulder armor, bridal gauntlets, purple nails, wide sleeves, mitsudomoe (shape), closed mouth, eyebrows visible through hair, long sleeves, floral print, simple background, nail polish, coattails, white background, musou isshin (genshin impact), braided ponytail\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0baee118eb4196b037dd68dbf1587d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: hatsune miku, 1girl, twintails, tongue, detached sleeves, tongue out, very long hair, looking at viewer, pleated skirt, black skirt, black legwear, holding food, zettai ryouiki, bare shoulders, holding candy, aqua eyes, hair ornament, hair between eyes, :p, black sleeves, miniskirt, collared shirt, eyebrows visible through hair, holding lollipop, aqua neckwear, nail polish, grey background, bangs, from above, small breasts, aqua nails, green neckwear, long sleeves, sleeves past wrists, light particles, gradient, aqua hair, gradient background, black thighhighs, aqua necktie, headphones, hatsune miku birthday festival 2021, vocaloid, this is good hatsune, miku must be an angel, this is good hatsune\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1a88ada44447b1915cbe633631f905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: hatsune miku, 1girl, twintails, detached sleeves, open mouth, musical note, black skirt, very long hair, pleated skirt, looking at viewer, cowboy shot, aqua hair, zettai ryouiki, bare shoulders, aqua eyes, black legwear, outstretched arms, aqua neckwear, black sleeves, hair ornament, miniskirt, :d, eyebrows visible through hair, beamed eighth notes, hair between eyes, shoulder tattoo, collared shirt, blue neckwear, character name, treble clef, long sleeves, blue necktie, vocaloid, hatsune miku 16th anniversary illustration, anniversary, aqua necktie, happy birthday\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ff41627ea54da48da629152a7379b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: hatsune miku, 1girl, detached sleeves, twintails, open mouth, looking at viewer, bare shoulders, upper body, sleeveless shirt, white background, hair ornament, aqua eyes, aqua hair, hair between eyes, aqua neckwear, collared shirt, shoulder tattoo, black sleeves, blue eyes, blue hair, :d, hand up, simple background, depth of field, blurry foreground, very long hair, close-up, blue neckwear, from side, light particles, vocaloid, aqua necktie, black skirt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed496b7a89c84ea6a9d235af33ef7301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: hatsune miku, 1girl, very long hair, japanese clothes, hair ornament, hair flower, twintails, absurdly long hair, standing, full body, outdoors, east asian architecture, aqua hair, looking at viewer, day, wide sleeves, black skirt, zettai ryouiki, aqua eyes, long sleeves, pleated skirt, floral print, floral playing cards, vocaloid, japanese style, beautiful, miku must be an angel, chinese style, beautiful legs, blue sky, bridge, hair between eyes, holding card, kimono dress, pink flower, purple flower, red bow, white kimono, white legwear\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from run_comfy_api import run_workflow, DEFAULT_NEG, DEFAULT_MODEL\n",
    "\n",
    "\n",
    "HARDCODED_MODEL_NAME = os.path.basename(os.path.normpath(MODEL_DIRS[0]))\n",
    "\n",
    "def gen_text_and_gen_image(rating: str, date: str, quality: str, character: str, prompt: str, max_length: int, \n",
    "                           seed: int, tags_front: str, tags_back: str) -> Tuple[str, List[str]]:\n",
    "    \n",
    "    selected_models = [HARDCODED_MODEL_NAME]\n",
    "    gend_text = []\n",
    "    gend_images = []\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for _ in range(4):\n",
    "            text_future = executor.submit(generate_text, rating, date, quality, character, prompt, max_length, 1, selected_models)\n",
    "            txt = text_future.result().split(\"\\n\")[0]\n",
    "            print(f\"Generated text: {txt}\")\n",
    "\n",
    "            # Add quality tags\n",
    "            txt = \", \".join([tags_front, txt, tags_back])\n",
    "            gend_text.append(txt)\n",
    "\n",
    "            image_future = executor.submit(run_workflow, pos=txt, \n",
    "                                           neg=\"lowres, worst quality, displeasing, bad quality, bad anatomy, text, error, extra digit, cropped, average quality, 2000s\",\n",
    "                                           seed=seed, batch_size=1)\n",
    "            _gend_images = image_future.result()\n",
    "            gend_images.extend(_gend_images)\n",
    "\n",
    "    # Save images and metadata in the background\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        executor.submit(save_images_and_metadata, gend_images, gend_text, prompt)\n",
    "    \n",
    "    return \"\\n\\n\".join(gend_text), gend_images\n",
    "    \n",
    "\n",
    "\n",
    "# Define Gradio interface components\n",
    "checkbox_choices = [os.path.basename(os.path.normpath(model_dir)) for model_dir in MODEL_DIRS]\n",
    "iface = gr.Interface(\n",
    "    fn=gen_text_and_gen_image,\n",
    "    inputs=[\n",
    "        gr.Radio(choices=[\"general\", \"nsfw\"], label=\"Rating\", value=\"general\"),\n",
    "        gr.Radio(choices=[\"2000s\", \"2010s\", \"2020s\"], label=\"Date\", value=\"2020s\"),\n",
    "        gr.Radio(choices=[\"normal\", \"good\", \"excellent\"], label=\"Quality\", value=\"excellent\"),\n",
    "        gr.Textbox(lines=1, placeholder=\"hatsune miku\", label=\"Character tags\"),\n",
    "        gr.Textbox(lines=2, placeholder=\"1girl, long hair, looking at viewer\", label=\"General Tags\"),\n",
    "        gr.Slider(minimum=40, maximum=300, value=180, step=10, label=\"Max Prompt Length\"),\n",
    "        gr.Number(value=-1, label=\"Image Generation Seed\"),\n",
    "        gr.Textbox(lines=1, value=\"best quality, 2020s\", label=\"tags_front\"),\n",
    "        gr.Textbox(lines=1, value=\"[[absurdres]]\", label=\"tags_back\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Generated Texts\"),\n",
    "        gr.Gallery(label=\"Generated Images\", height=768),\n",
    "    ],\n",
    "    title=\"Prompt Augment and SDXL New Model Demo\",\n",
    "    description=\"\"\"\n",
    "Pipeline:\n",
    "  - input some danbooru tags (or danbooru-like tags)\n",
    "  - augment the input to match the model training distribution\n",
    "  - generate images from the augmented input (by calling ComfyUI API)\n",
    "  - receives output\n",
    "\n",
    "Input tags is in danbooru format (or similar): \n",
    "  - see: https://danbooru.donmai.us/posts/7793852\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
