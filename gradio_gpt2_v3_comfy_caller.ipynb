{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT V3\n",
    "\n",
    "单个模型(fixed), 直接对接到webui (生成很多个), 所以产生一行一个的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import gradio as gr\n",
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "import os\n",
    "import hashlib\n",
    "import json\n",
    "from datetime import datetime\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "# Assuming DEVICE is already defined\n",
    "DEVICE = 'cuda'  # Use 'cuda' for GPU or 'cpu' for CPU\n",
    "\n",
    "# Path to the models' directories\n",
    "MODEL_DIRS = [\n",
    "    'pixiv-prompts-gpt-finetunes/8xh100_run2_e2_s50k',\n",
    "]\n",
    "\n",
    "# Load the model and tokenizer from the directory\n",
    "MODEL_NAME = os.path.basename(os.path.normpath(MODEL_DIRS[0]))\n",
    "model = transformers.GPT2LMHeadModel.from_pretrained(MODEL_DIRS[0]).to(DEVICE).eval()\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_DIRS[0])\n",
    "\n",
    "def generate_text(rating: str, date: str, quality: str, character: str, prompt: str, max_length: int, num_lines: int):\n",
    "    \"\"\"Generate text based on input prompt.\"\"\"\n",
    "    query_prompt = f'<input rating=\"{rating}\" chara=\"{character}\" date=\"{date}\" quality=\"{quality}\" tags=\"{prompt}\">'\n",
    "    query_prompt += \"<output>\"\n",
    "\n",
    "    all_outputs = []\n",
    "    for _ in range(num_lines):\n",
    "        input_ids = tokenizer.encode(query_prompt, return_tensors='pt').to(DEVICE)\n",
    "        output_sequences = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_length=max_length + len(input_ids[0]),\n",
    "            temperature=1.0,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            repetition_penalty=1.0,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "\n",
    "        generated_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "\n",
    "        # Find and remove the initial part up to <output>\n",
    "        start_output = generated_text.find(\"<output>\") + len(\"<output>\")\n",
    "        generated_text = generated_text[start_output:].strip()\n",
    "\n",
    "        # Remove the ending </output> tag or truncate at last complete tag\n",
    "        end_tag = generated_text.find(\"</output>\")\n",
    "        if end_tag != -1:\n",
    "            generated_text = generated_text[:end_tag]\n",
    "        else:\n",
    "            last_comma = generated_text.rfind(\",\")\n",
    "            if last_comma != -1:\n",
    "                generated_text = generated_text[:last_comma]\n",
    "\n",
    "        all_outputs.append(generated_text.strip())\n",
    "\n",
    "    # Join all outputs into a single string separated by new lines\n",
    "    return \"\\n\".join(all_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_OUTPUT_DIR = \"generated_images\"\n",
    "\n",
    "\n",
    "def save_images_and_metadata(gend_images, gend_text, prompt):\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(IMG_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    for image in gend_images:\n",
    "        # Get filename\n",
    "        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        img_hash = hashlib.md5(image.tobytes()).hexdigest()        \n",
    "        file_name = f\"{timestamp}_{img_hash[:4]}.webp\"        \n",
    "        file_path = os.path.join(IMG_OUTPUT_DIR, file_name)\n",
    "        \n",
    "        # Save image\n",
    "        image.save(file_path, format='WEBP')\n",
    "\n",
    "        # Create metadata JSON\n",
    "        metadata = {\n",
    "            \"prompt\": prompt,\n",
    "            \"generated_text\": gend_text,\n",
    "        }\n",
    "        json_file_name = f\"{timestamp}_{img_hash[:4]}.json\"\n",
    "        json_file_path = os.path.join(IMG_OUTPUT_DIR, json_file_name)\n",
    "        \n",
    "        with open(json_file_path, 'w') as json_file:\n",
    "            json.dump(metadata, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "Running on public URL: https://5deef8067c2d7e3271.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5deef8067c2d7e3271.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: hatsune miku, 1girl, twintails, very long hair, day, blue sky, aqua hair, outdoors, aqua eyes, arms up, cowboy shot, black pants, hair ribbon, track pants, black shorts, open clothes, hood down, pink jacket, smile, hair between eyes, long sleeves, open jacket, closed mouth, floating hair, from side, blue hair, blurry foreground, looking up, bangs, looking afar, yellow shirt, looking away, hooded jacket, drawstring, red jacket, wind, vocaloid, beautiful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: hatsune miku, 1girl, twintails, very long hair, open mouth, black legwear, blue hair, cowboy shot, sleeveless shirt, looking at viewer, floating hair, blue neckwear, hair between eyes, collared shirt, bare shoulders, zettai ryouiki, :d, blue eyes, aqua neckwear, hair ornament, hand up, aqua hair, bangs, standing, pleated skirt, bare arms, grey background, arm behind back, black skirt, hand on own chest, hand on own face, light particles\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from run_comfy_api import run_workflow, DEFAULT_NEG, DEFAULT_MODEL\n",
    "\n",
    "\n",
    "HARDCODED_MODEL_NAME = os.path.basename(os.path.normpath(MODEL_DIRS[0]))\n",
    "\n",
    "def gen_text_and_gen_image(rating: str, date: str, quality: str, character: str, prompt: str, max_length: int, \n",
    "                           img_count:int, seed: int, tags_front: str, tags_back: str) -> Tuple[str, List[str]]:\n",
    "    \n",
    "    gend_text = []\n",
    "    gend_images = []\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for _ in range(img_count):\n",
    "            text_future = executor.submit(generate_text, rating, date, quality, character, prompt, max_length, 1)\n",
    "            txt = text_future.result().split(\"\\n\")[0]\n",
    "            print(f\"Generated text: {txt}\")\n",
    "\n",
    "            # Add quality tags\n",
    "            txt = \", \".join([tags_front, txt, tags_back])\n",
    "            gend_text.append(txt)\n",
    "\n",
    "            image_future = executor.submit(run_workflow, pos=txt, \n",
    "                                           neg=\"lowres, worst quality, displeasing, bad quality, bad anatomy, text, error, extra digit, cropped, average quality, 2000s\",\n",
    "                                           seed=seed, batch_size=1)\n",
    "            _gend_images = image_future.result()\n",
    "            gend_images.extend(_gend_images)\n",
    "\n",
    "    # Save images and metadata in the background\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        executor.submit(save_images_and_metadata, gend_images, gend_text, prompt)\n",
    "    \n",
    "    return \"\\n\\n\".join(gend_text), gend_images\n",
    "    \n",
    "\n",
    "# Wrapper function for the default tab with preset parameters\n",
    "def gen_text_and_gen_image_default(rating, character, prompt, num_images):\n",
    "    date = \"2020s\"\n",
    "    quality = \"excellent\"\n",
    "\n",
    "    return gen_text_and_gen_image(rating, date, quality, character, prompt, max_length= 120, \n",
    "                                  img_count=num_images, seed=-1, tags_front=\"best quality, 2020s\", tags_back=\"[[absurdres]]\"\n",
    "                                  )\n",
    "\n",
    "# Define Gradio interface components for the advanced tab\n",
    "checkbox_choices = [os.path.basename(os.path.normpath(model_dir)) for model_dir in MODEL_DIRS]\n",
    "\n",
    "advanced_inputs = [\n",
    "    gr.Radio(choices=[\"general\", \"nsfw\"], label=\"Rating\", value=\"general\"),\n",
    "    gr.Radio(choices=[\"2000s\", \"2010s\", \"2020s\"], label=\"Date\", value=\"2020s\"),\n",
    "    gr.Radio(choices=[\"normal\", \"good\", \"excellent\"], label=\"Quality\", value=\"excellent\"),\n",
    "    gr.Textbox(lines=1, placeholder=\"hatsune miku\", label=\"Character tags\"),\n",
    "    gr.Textbox(lines=2, placeholder=\"1girl, long hair, looking at viewer\", label=\"General Tags\"),\n",
    "    gr.Slider(minimum=40, maximum=300, value=120, step=10, label=\"Max Prompt Length\"),\n",
    "    gr.Slider(minimum=1, maximum=4, value=2, step=1, label=\"Image Generation Count\"),\n",
    "    gr.Number(value=-1, label=\"Image Generation Seed\"),\n",
    "    gr.Textbox(lines=1, value=\"best quality, 2020s\", label=\"tags_front\"),\n",
    "    gr.Textbox(lines=1, value=\"[[absurdres]]\", label=\"tags_back\"),\n",
    "]\n",
    "\n",
    "advanced_outputs = [\n",
    "    gr.Textbox(label=\"Generated Texts\"),\n",
    "    gr.Gallery(label=\"Generated Images\", height=768),\n",
    "]\n",
    "\n",
    "# Define Gradio interface components for the default tab\n",
    "default_inputs = [\n",
    "    gr.Radio(choices=[\"general\", \"nsfw\"], label=\"Rating\", value=\"general\"),\n",
    "    gr.Textbox(lines=1, placeholder=\"hatsune miku\", label=\"Character tags\"),\n",
    "    gr.Textbox(lines=2, placeholder=\"1girl, long hair, looking at viewer\", label=\"General Tags\"),\n",
    "    gr.Slider(minimum=1, maximum=4, value=2, step=1, label=\"Image Generation Count\"),\n",
    "]\n",
    "\n",
    "default_outputs = [\n",
    "    gr.Textbox(label=\"Generated Texts\"),\n",
    "    gr.Gallery(label=\"Generated Images\", height=768),\n",
    "]\n",
    "\n",
    "# Define the interface with two tabs\n",
    "iface = gr.TabbedInterface(\n",
    "    [\n",
    "        gr.Interface(\n",
    "            fn=gen_text_and_gen_image_default,\n",
    "            inputs=default_inputs,\n",
    "            outputs=default_outputs,\n",
    "            title=\"Default\",\n",
    "            description=\"Simple interface with preset values.\",\n",
    "        ),\n",
    "        gr.Interface(\n",
    "            fn=gen_text_and_gen_image,\n",
    "            inputs=advanced_inputs,\n",
    "            outputs=advanced_outputs,\n",
    "            title=\"Advanced\",\n",
    "            description=\"Advanced interface with customizable parameters.\",\n",
    "        ),\n",
    "    ],\n",
    "    [\"Default\", \"Advanced\"],\n",
    "    title=\"\"\"\n",
    "\n",
    "# Prompt Augment and SDXL New Model Demo\n",
    "    \n",
    "Pipeline:\n",
    "  - input some danbooru tags (or danbooru-like tags)\n",
    "  - augment the input to match the model training distribution\n",
    "  - generate images from the augmented input (by calling ComfyUI API)\n",
    "  - receives output\n",
    "\n",
    "Input tags is in danbooru format (or similar): \n",
    "  - see: https://danbooru.donmai.us/posts/7793852\n",
    "\n",
    "**Use The Default Tag for more granular controls**\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
