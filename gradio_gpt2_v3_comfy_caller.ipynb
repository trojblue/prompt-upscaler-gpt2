{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT V3\n",
    "\n",
    "单个模型(fixed), 直接对接到webui (生成很多个), 所以产生一行一个的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import gradio as gr\n",
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "import os\n",
    "import hashlib\n",
    "import json\n",
    "from datetime import datetime\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "# Assuming DEVICE is already defined\n",
    "DEVICE = 'cuda'  # Use 'cuda' for GPU or 'cpu' for CPU\n",
    "\n",
    "# Path to the models' directories\n",
    "MODEL_DIRS = [\n",
    "    'pixiv-prompts-gpt-finetunes/8xh100_run2_e2_s50k',\n",
    "]\n",
    "\n",
    "# Load the model and tokenizer from the directory\n",
    "MODEL_NAME = os.path.basename(os.path.normpath(MODEL_DIRS[0]))\n",
    "model = transformers.GPT2LMHeadModel.from_pretrained(MODEL_DIRS[0]).to(DEVICE).eval()\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_DIRS[0])\n",
    "\n",
    "def generate_text(rating: str, date: str, quality: str, character: str, prompt: str, max_length: int, num_lines: int):\n",
    "    \"\"\"Generate text based on input prompt.\"\"\"\n",
    "    query_prompt = f'<input rating=\"{rating}\" chara=\"{character}\" date=\"{date}\" quality=\"{quality}\" tags=\"{prompt}\">'\n",
    "    query_prompt += \"<output>\"\n",
    "\n",
    "    all_outputs = []\n",
    "    for _ in range(num_lines):\n",
    "        input_ids = tokenizer.encode(query_prompt, return_tensors='pt').to(DEVICE)\n",
    "        output_sequences = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_length=max_length + len(input_ids[0]),\n",
    "            temperature=1.0,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            repetition_penalty=1.0,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "\n",
    "        generated_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "\n",
    "        # Find and remove the initial part up to <output>\n",
    "        start_output = generated_text.find(\"<output>\") + len(\"<output>\")\n",
    "        generated_text = generated_text[start_output:].strip()\n",
    "\n",
    "        # Remove the ending </output> tag or truncate at last complete tag\n",
    "        end_tag = generated_text.find(\"</output>\")\n",
    "        if end_tag != -1:\n",
    "            generated_text = generated_text[:end_tag]\n",
    "        else:\n",
    "            last_comma = generated_text.rfind(\",\")\n",
    "            if last_comma != -1:\n",
    "                generated_text = generated_text[:last_comma]\n",
    "\n",
    "        all_outputs.append(generated_text.strip())\n",
    "\n",
    "    # Join all outputs into a single string separated by new lines\n",
    "    return \"\\n\".join(all_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_OUTPUT_DIR = \"generated_images\"\n",
    "\n",
    "\n",
    "def save_images_and_metadata(gend_images, gend_text, prompt):\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(IMG_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    for image in gend_images:\n",
    "        # Get filename\n",
    "        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        img_hash = hashlib.md5(image.tobytes()).hexdigest()        \n",
    "        file_name = f\"{timestamp}_{img_hash[:4]}.webp\"        \n",
    "        file_path = os.path.join(IMG_OUTPUT_DIR, file_name)\n",
    "        \n",
    "        # Save image\n",
    "        image.save(file_path, format='WEBP')\n",
    "\n",
    "        # Create metadata JSON\n",
    "        metadata = {\n",
    "            \"prompt\": prompt,\n",
    "            \"generated_text\": gend_text,\n",
    "        }\n",
    "        json_file_name = f\"{timestamp}_{img_hash[:4]}.json\"\n",
    "        json_file_path = os.path.join(IMG_OUTPUT_DIR, json_file_name)\n",
    "        \n",
    "        with open(json_file_path, 'w') as json_file:\n",
    "            json.dump(metadata, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://248f7375fffcaccf75.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://248f7375fffcaccf75.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: yoisaki kanade, 1girl, japanese clothes, hair ornament, oil-paper umbrella, hair flower, open mouth, looking at viewer, holding umbrella, nail polish, floral print, hair between eyes, eyebrows visible through hair, wide sleeves, bangs, long sleeves, red flower, upper body, print kimono, outdoors, depth of field, brown eyes, blurry background, blurry foreground, from side, :o, red nails, looking to the side, hand up, white flower, red eyes, lens flare, white background, grey kimono\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: yoisaki kanade, 1girl, hair between eyes, long sleeves, parted lips, very long hair, looking at viewer, collarbone, sleeves past wrists, holding envelope, star (symbol), hands up, grey background, simple background, blush, brown sweater, grey bow, eyebrows visible through hair, holding letter, grey ribbon, upper body, white background, black bow, project sekai, 25-ji, night code de., prsk_fa, hair ornament\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from run_comfy_api import run_workflow, DEFAULT_NEG, DEFAULT_MODEL\n",
    "\n",
    "\n",
    "HARDCODED_MODEL_NAME = os.path.basename(os.path.normpath(MODEL_DIRS[0]))\n",
    "\n",
    "def gen_text_and_gen_image(rating: str, date: str, quality: str, character: str, prompt: str, max_length: int, \n",
    "                           img_count:int, seed: int, tags_front: str, tags_back: str) -> Tuple[str, List[str]]:\n",
    "    \n",
    "    gend_text = []\n",
    "    gend_images = []\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for _ in range(img_count):\n",
    "            text_future = executor.submit(generate_text, rating, date, quality, character, prompt, max_length, 1)\n",
    "            txt = text_future.result().split(\"\\n\")[0]\n",
    "            print(f\"Generated text: {txt}\")\n",
    "\n",
    "            # Add quality tags\n",
    "            txt = \", \".join([tags_front, txt, tags_back])\n",
    "            gend_text.append(txt)\n",
    "\n",
    "            image_future = executor.submit(run_workflow, pos=txt, \n",
    "                                           neg=\"lowres, worst quality, displeasing, bad quality, bad anatomy, text, error, extra digit, cropped, average quality, 2000s\",\n",
    "                                           seed=seed, batch_size=1)\n",
    "            _gend_images = image_future.result()\n",
    "            gend_images.extend(_gend_images)\n",
    "\n",
    "    # Save images and metadata in the background\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        executor.submit(save_images_and_metadata, gend_images, gend_text, prompt)\n",
    "    \n",
    "    return \"\\n\\n\".join(gend_text), gend_images\n",
    "    \n",
    "\n",
    "# Define Gradio interface components\n",
    "checkbox_choices = [os.path.basename(os.path.normpath(model_dir)) for model_dir in MODEL_DIRS]\n",
    "iface = gr.Interface(\n",
    "    fn=gen_text_and_gen_image,\n",
    "    inputs=[\n",
    "        gr.Radio(choices=[\"general\", \"nsfw\"], label=\"Rating\", value=\"general\"),\n",
    "        gr.Radio(choices=[\"2000s\", \"2010s\", \"2020s\"], label=\"Date\", value=\"2020s\"),\n",
    "        gr.Radio(choices=[\"normal\", \"good\", \"excellent\"], label=\"Quality\", value=\"excellent\"),\n",
    "        gr.Textbox(lines=1, placeholder=\"hatsune miku\", label=\"Character tags\"),\n",
    "        gr.Textbox(lines=2, placeholder=\"1girl, long hair, looking at viewer\", label=\"General Tags\"),\n",
    "        gr.Slider(minimum=40, maximum=300, value=120, step=10, label=\"Max Prompt Length\"),\n",
    "        gr.Slider(minimum=1, maximum=4, value=2, step=1, label=\"Image Generation Count\"),\n",
    "        gr.Number(value=-1, label=\"Image Generation Seed\"),\n",
    "        gr.Textbox(lines=1, value=\"best quality, 2020s\", label=\"tags_front\"),\n",
    "        gr.Textbox(lines=1, value=\"[[absurdres]]\", label=\"tags_back\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Generated Texts\"),\n",
    "        gr.Gallery(label=\"Generated Images\", height=768),\n",
    "    ],\n",
    "    title=\"Prompt Augment and SDXL New Model Demo\",\n",
    "    description=\"\"\"\n",
    "Pipeline:\n",
    "  - input some danbooru tags (or danbooru-like tags)\n",
    "  - augment the input to match the model training distribution\n",
    "  - generate images from the augmented input (by calling ComfyUI API)\n",
    "  - receives output\n",
    "\n",
    "Input tags is in danbooru format (or similar): \n",
    "  - see: https://danbooru.donmai.us/posts/7793852\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
