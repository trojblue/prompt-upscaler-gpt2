{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from PIL import Image, PngImagePlugin\n",
    "\n",
    "import unibox as ub\n",
    "logger = ub.UniLogger()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt2 client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt2 api\n",
    "from gradio_client import Client\n",
    "\n",
    "def get_gpt2_pred_old(client, prompt:str, max_length:int, models:list[str]):\n",
    "\t# prompt: str\n",
    "\t# max_length: float (numeric value between 10 and 300)\n",
    "\t# return: str\n",
    "\tresult = client.predict(\n",
    "\t\tprompt,\n",
    "\t\tmax_length,\n",
    "\t\tmodels,\n",
    "\t\tapi_name=\"/predict\"\n",
    "\t)\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_gpt2_pred(client, rating:str, character:str, prompt:str, max_length:int, models:list[str]):\n",
    "\t\n",
    "\tassert rating in ['general','nsfw']\n",
    "\t\n",
    "\tresult = client.predict(\n",
    "\t\t\trating,\t# Literal['safe', 'sensitive', 'nsfw', 'nsfw, explicit'] in 'Rating' Radio component\n",
    "\t\t\t\"2020s\",\t# Literal['2000s', '2010s', '2015s', '2020s'] in 'Date' Radio component\n",
    "\t\t\t\"excellent\",\t# Literal['bad', 'normal', 'good', 'excellent'] in 'Quality' Radio component\n",
    "\t\t\tcharacter,\t# str in 'Character' Textbox component\n",
    "\t\t\tprompt,\t# str in 'prompt' Textbox component\n",
    "\t\t\tmax_length,\t# float (numeric value between 40 and 300) in 'max_length' Slider component\n",
    "\t\t\tmodels,\t# List[Literal['checkpoint-e0_s12000', 'checkpoint-e0_s28000', 'checkpoint-e0_s48000']] in 'Select Models' Checkboxgroup component\n",
    "\t\t\tapi_name=\"/predict\"\n",
    "\t)\n",
    "\treturn result\n",
    "\n",
    "\n",
    "# GPT2_ENDPOINT = \"https://ab2b7e0b874cc07fb9.gradio.live/\"\n",
    "# client = Client(GPT2_ENDPOINT) # version epoch_0_batch_11727\n",
    "# get_gpt2_pred(client, \"hatsune miku\", 100, [\"epoch_0_batch_17619\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "webui:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/troph-team/eval-it/blob/aa0cb59983e2b0385ef03328b2ce6a3c36a073a0/evalit/webui/webui_t2i_client.py#L38C7-L38C27\n",
    "from evalit.webui.webui_t2i_client import WebuiT2iClient\n",
    "from evalit.webui.webui_t2i_client import WebuiT2iClient, SdxlGenerationConfig\n",
    "from evalit.webui.webui_options_manager import OptionsManager\n",
    "\n",
    "\n",
    "def save_image(image_paths:list[str], param_strs:list[str], api_args, save_dir:str=\"saved_images\"):\n",
    "    \"\"\"保存一个webui生成结果到本地 (可能包括多张图)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    saved_files = []\n",
    "\n",
    "    for i, (image, param) in enumerate(zip(image_paths, param_strs)):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        pnginfo = PngImagePlugin.PngInfo()\n",
    "        pnginfo.add_text(\"parameters\", param)\n",
    "        pnginfo.add_text(\"api_args\", json.dumps(api_args))\n",
    "\n",
    "        # get filename\n",
    "        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        img_hash = hashlib.md5(image.tobytes()).hexdigest()        \n",
    "        file_name = f\"{timestamp}_{img_hash[:4]}.png\"        \n",
    "        file_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "        # save file\n",
    "        image.save(file_path, pnginfo=pnginfo)\n",
    "        saved_files.append(file_path)  # Add the saved file path to the list\n",
    "\n",
    "    return saved_files\n",
    "\n",
    "def generate_and_save_images(prompt:str, config:SdxlGenerationConfig, save_dir:str=\"saved_images\",):\n",
    "    \"\"\"从webui api roll图, 然后返回本地保存路径\n",
    "    (假设模型已经在webui里手动调到需要的那个)\n",
    "    \"\"\"\n",
    "    # initialize client\n",
    "    client = WebuiT2iClient(baseurl=\"http://0.0.0.0:7862\")\n",
    "\n",
    "    # initialize options manager\n",
    "    client_base_url = client.baseurl\n",
    "    options_manager = OptionsManager(client_base_url)\n",
    "\n",
    "\n",
    "    # generate images\n",
    "    images, param_strs, api_args = client.generate(prompt, config)  # negative defined in config\n",
    "\n",
    "    # save images\n",
    "    saved_files = save_image(images, param_strs, api_args, save_dir) # list of paths to saved images\n",
    "    return saved_files\n",
    "\n",
    "# save_dir = \"saved_images\"\n",
    "# img_path = generate_and_save_images(\"a cat\")[0]\n",
    "# display(ub.loads(img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://44b07123159cab6c40.gradio.live/ ✔\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import random\n",
    "import timeit\n",
    "\n",
    "\n",
    "def get_sdxl_generation_config(steps:int=32):\n",
    "    \"\"\"returns a SdxlGenerationConfig object with modifiable steps param\n",
    "    \"\"\"\n",
    "    \n",
    "    # SDXL generation config\n",
    "    # https://github.com/troph-team/eval-it/blob/aa0cb59983e2b0385ef03328b2ce6a3c36a073a0/evalit/webui/webui_t2i_client.py#L38  \n",
    "    config = SdxlGenerationConfig() \n",
    "    config.sampler_name=\"Euler a\"\n",
    "    config.cfg_scale=6.5\n",
    "    config.height=1280\n",
    "    config.width=768\n",
    "    config.steps=steps\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def roll_image(prompt:str, character:str = \"\", rating:str=\"general\", img_steps:int=32, prompt_only:bool=False):\n",
    "    \n",
    "    # rating = random.choice([\"general\", \"nsfw\"])    \n",
    "    prompt_len = 200\n",
    "    # img_steps = 28\n",
    "\n",
    "    # get sdxl config\n",
    "    config = get_sdxl_generation_config(steps=img_steps)\n",
    "    \n",
    "    orig_prompt = prompt\n",
    "    logger.info(f\"got prompt: {prompt} | character: {character} | rating: {rating}\")\n",
    "\n",
    "    # get gpt2 predictions\n",
    "    gpt2_res = get_gpt2_pred(client, rating, character, prompt, prompt_len, gpt2_models)\n",
    "    logger.info(f\"got gpt2 res of len={len(gpt2_res)}\")\n",
    "\n",
    "    \n",
    "    gpt2_res.pop(\"original\", None)          # drop key 'original'\n",
    "    prompt_str = list(gpt2_res.values())[0] # choose only one since working with only one\n",
    "    prompt_str = prompt_str.replace(\"</output>\", \"\")\n",
    "    print(prompt_str)\n",
    "\n",
    "    if prompt_only:\n",
    "        return prompt_str, None\n",
    "    \n",
    "    # generate image \n",
    "    img_start_time = timeit.default_timer()\n",
    "    saved_files = generate_and_save_images(prompt=prompt_str, config=config)\n",
    "    logger.info(f\"prompt: {prompt_str} | image: {saved_files}\")\n",
    "    img_end_time = timeit.default_timer()\n",
    "\n",
    "    # load iamge paths to PIL\n",
    "    image_path = saved_files[0]\n",
    "    img = ub.loads(image_path, debug_print=False)\n",
    "    load_img_end_time = timeit.default_timer()\n",
    "    print(f\"img roll time: {img_end_time - img_start_time:.2f}s | img response time: {load_img_end_time - img_end_time:.2f}s\")\n",
    "\n",
    "    return prompt_str, img\n",
    "\n",
    "\n",
    "gpt2_models = ['8xh100_run2_e2_s50k',]\n",
    "GPT2_ENDPOINT = \"https://44b07123159cab6c40.gradio.live\"\n",
    "client = Client(GPT2_ENDPOINT) # version epoch_0_batch_11727"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 22:23:48,659 [INFO] UniLogger: UniLoader.loads: .json LOADED from \"/tmp/tmpks5zn3ll/danbooru_meta_tag_string_character_counter_20240209.json\" in 0.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214681\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from dataproc3.caption_builder_v2.caption_build_methods import safe_split_tag_str, safe_concat\n",
    "\n",
    "def display_results(prompt, img):\n",
    "    # display(prompt)\n",
    "    img.thumbnail((1024, 1024))\n",
    "    display(img)\n",
    "\n",
    "def split_input(input_str:str):\n",
    "    \"\"\"split input into character and general tags\n",
    "    \"\"\"\n",
    "    character_tags = []\n",
    "    general_tags = []\n",
    "    input_tags = safe_split_tag_str(input_str)\n",
    "    for tag in input_tags:\n",
    "        if tag.replace(\" \", \"_\").lower() in dbr_character_tags:\n",
    "            character_tags.append(tag)\n",
    "        else:\n",
    "            general_tags.append(tag.replace(\"_\", \" \"))\n",
    "\n",
    "    _general_input = safe_concat(*general_tags)\n",
    "    _character_input = safe_concat(*character_tags)\n",
    "    return _general_input, _character_input\n",
    "\n",
    "dbr_character_tags = ub.loads(\"s3://unidataset-danbooru/metadata/tag_counters/danbooru_meta_tag_string_character_counter_20240209.json\").keys()\n",
    "dbr_character_tags = set(dbr_character_tags)\n",
    "print(len(dbr_character_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"\"\"\n",
    " long sleeves, pink background, upper body, sidelocks\n",
    " \"\"\".strip()\n",
    "\n",
    "\n",
    "while True:\n",
    "    _general_input, _character_input = split_input(input_str)\n",
    "    prompt_res, img = roll_image(_general_input, character=_character_input, rating=\"general\")\n",
    "    display_results(prompt_res, img)\n",
    "    ramdom_tags = random.choices(safe_split_tag_str(prompt_res), k=4)\n",
    "    input_str = safe_concat(*ramdom_tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
